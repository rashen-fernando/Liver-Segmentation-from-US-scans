# -*- coding: utf-8 -*-
"""Deeplab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11wVMJQTobIPLE0QFQBPYfPBnBTGfa51A
"""

#@title Importing libraries
import numpy as np
import os
from matplotlib import pylab as plt

from skimage.transform import resize
from skimage import color

from tqdm import tqdm
import pickle
import torch
import torch.nn as nn
import torch.nn.functional as F

import torchvision.transforms.functional as fn
import math
import joblib

# import neptune.new as neptune
# from neptune.new.types import File
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

#@title Depthwise Separable convolution
class SepConv2d(nn.Module):
    def __init__(self, nin, nout,kernal,stride,padding):
        super().__init__()
        self.depthwise = nn.Conv2d(nin, nin, kernel_size=kernal,stride=stride,padding=padding)
        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)

    def forward(self, x):
        out = self.depthwise(x)
        out = self.pointwise(out)
        return out


#@title Middel flow
class Middle_flow(nn.Module):
    def __init__(self, nin, nout,kernal):
        super().__init__()
        self.c1 = SepConv2d(nin, nout,kernal,1,1)
        self.c2 = SepConv2d(nin, nout,kernal,1,1)
        self.norm = nn.BatchNorm2d(728)
        self.c3 = SepConv2d(nin, nout,kernal,1,1)
      
    def forward(self, x):
        skip = x
        x = self.c1(x)
        x = self.norm(self.c2(x))
        x = F.rrelu(self.c3(x))
        x = skip + x

        return x


#@title Arous Spatial Pooling
class ASPP(nn.Module):
    def __init__(self, nin, output_size):
        super().__init__()
        self.pool  = nn.AvgPool2d(3, stride=1)
        self.c1 = nn.Conv2d(nin, 256,1)
        self.norm1 = nn.BatchNorm2d(256)
        self.m1 = nn.Upsample(output_size, mode='bilinear')

        self.c2 = nn.Conv2d(nin, 256,3,stride=16,dilation = 6)
        self.norm2 = nn.BatchNorm2d(256)
        self.m2 = nn.Upsample(output_size, mode='bilinear')
        
        self.c3 = nn.Conv2d(nin, 256,3,stride=16,dilation = 12)
        self.norm3 = nn.BatchNorm2d(256)
        self.m3 = nn.Upsample(output_size, mode='bilinear')
        
        self.c4 = nn.Conv2d(nin, 256,3,stride=8,dilation = 18)
        self.norm4 = nn.BatchNorm2d(256)
        self.m5 = nn.Upsample((37,37), mode='bilinear')
        self.m4 = nn.Upsample(output_size, mode='bilinear')
        
    def forward(self, x):
        x = self.pool(x)
        x1 = self.m1(self.norm1(self.c1(x )))
        x2 = self.m2(self.norm2(self.c2(x ))) 
        x3 = self.m3(self.norm3(self.c3(self.m3(x) ))) 
        x4 = self.m4(self.norm3(self.c4(self.m5(x) ))) 
        x = torch.cat((x1,x2,x3,x4),dim = 1)

        return x


#@title Xception
class Xception(nn.Module):
    def __init__(self, batch_size,Channel_size,Input_size):
      super().__init__()
      #example -- > batch size 8 , channels -3 , image width and height -512x512
      
      #entryflow
      self.c1 = nn.Conv2d(Channel_size,32,3,stride = 2)
      self.c2 = nn.Conv2d(32,64,3)
      
      self.c3 = SepConv2d(64,128,3,1,1)
      self.c4 = SepConv2d(128,128,3,1,1)
      self.norm1 = nn.BatchNorm2d(128)
      self.c5 = SepConv2d(128,128,3,2,1)

      self.c6 = SepConv2d(128,256,3,1,1)
      self.c7 = SepConv2d(256,256,3,1,1)
      self.norm2 = nn.BatchNorm2d(256)
      self.c8 = SepConv2d(256,256,3,2,1)

      self.c9 = SepConv2d(256,728,3,1,1)
      self.c10 = SepConv2d(728,728,3,1,1)
      self.norm3 = nn.BatchNorm2d(728)
      self.c11 = SepConv2d(728,728,3,2,1)

      self.c12 = SepConv2d(728,728,3,1,1)
      self.c13 = SepConv2d(728,1024,3,1,1)
      self.norm4 = nn.BatchNorm2d(1024)
      self.c14 = SepConv2d(1024,1024,3,2,1)
      
      self.c15 = SepConv2d(1024,1536,3,1,1)
      self.c16 = SepConv2d(1536,1536,3,1,1)
      self.norm5 = nn.BatchNorm2d(1536)
      self.c17 = SepConv2d(1536,2048,3,1,1)
      
      self.SkipConv1 = nn.Conv2d(64,128,1,stride = 2)
      self.SkipConv2 = nn.Conv2d(128,256,1,stride = 2)
      self.SkipConv3 = nn.Conv2d(256,728,1,stride = 2)
      self.SkipConv4 = nn.Conv2d(728,1024,1,stride = 2)

      self.m1 = Middle_flow(728,728,3)
      self.m2 = Middle_flow(728,728,3)
      self.m3 = Middle_flow(728,728,3)
      self.m4 = Middle_flow(728,728,3)
      self.m5 = Middle_flow(728,728,3)
      self.m6 = Middle_flow(728,728,3)
      self.m7 = Middle_flow(728,728,3)
      self.m8 = Middle_flow(728,728,3)
      self.m9 = Middle_flow(728,728,3)
      self.m10 = Middle_flow(728,728,3)
      self.m11 = Middle_flow(728,728,3)
      self.m12 = Middle_flow(728,728,3)
      self.m13 = Middle_flow(728,728,3)
      self.m14 = Middle_flow(728,728,3)
      self.m15 = Middle_flow(728,728,3)
      self.m16 = Middle_flow(728,728,3)
      
      
      self.SPP = ASPP(2048,(32,32))

    def forward(self,x):
      #entry flow
      x = self.c1(x)
      x = self.c2(x)
      skip = self.SkipConv1(x) #[8, 128, 127, 127]
      

      x = self.c3(x)
      x = self.norm1(self.c4(x))
      x = F.rrelu(self.c5(x)) #[8, 128, 127, 127]
      x = x+skip
      skipout = x
      skip = self.SkipConv2(x) #[8, 256, 64, 64]

      x = self.c6(x)
      x = self.norm2(self.c7(x))
      x = F.rrelu(self.c8(x)) #[8, 256, 64, 64]
      x = x+skip
      skip = self.SkipConv3(x) #[8, 728, 32, 32]

      
      x = self.c9(x)
      x = self.norm3(self.c10(x))
      x = F.rrelu(self.c11(x)) #[8, 728, 32, 32]
      x = x+skip

      #midflow
      x = self.m1(x) #[8, 728, 32, 32]
      x = self.m2(x)
      x = self.m3(x)
      x = self.m4(x)
      x = self.m5(x)
      x = self.m6(x)
      x = self.m7(x)
      x = self.m8(x)
      x = self.m9(x)
      x = self.m10(x)
      x = self.m11(x)
      x = self.m12(x)
      x = self.m13(x)
      x = self.m14(x)
      x = self.m15(x)
      x = self.m16(x) #[8, 728, 32, 32]

      #exit flow
      skip = x
      skip = self.SkipConv4(x)  #[8, 1024, 16, 16]

      x = self.c12(x)
      x = self.norm4(self.c13(x))
      x = F.rrelu(self.c14(x)) #[8, 1024, 16, 16]
      x = x+skip
      
      x = self.c15(x)
      x = self.norm5(self.c16(x))
      x = F.rrelu(self.c17(x)) #[8, 2048, 16, 16]

      x =self.SPP(x)
      
      return x,skipout
      



#@title Deeplab v3
class Deeplabv3(nn.Module):
    def __init__(self, batch_size,Channel_size,Input_size):
        super().__init__()
        self.Xception_Model =Xception(batch_size,Channel_size,Input_size)
        self.c1 = nn.Conv2d(1024,256,1)
        self.m1 = nn.Upsample(scale_factor = 4, mode='bilinear')

        self.c2 = nn.Conv2d(128,256,2,padding = 1)
        self.c3 = nn.Conv2d(512,1,3,stride =1,padding = 1)
        self.m2 = nn.Upsample(scale_factor = 4, mode='bilinear')
      
    def forward(self, x):
        x,skip = self.Xception_Model(x) #[8, 1024, 32, 32]
        skip = self.c2(skip) #[2, 256, 128, 128]

        x = self.c1(x) #[8, 256, 32, 32]
        x = self.m1(x) #[8, 256, 128, 128]

        x = torch.cat((x,skip),dim =1)
        x = self.m2(self.c3(x))
        return x



train_dir = input('Training Data Path (.pt extension) - ')
Ground_truth_dir = input('Ground Truth Data Path (.pt extension) - ')

X = torch.load(train_dir)#, map_location=torch.device(device))
Y = torch.load(Ground_truth_dir)#, map_location=torch.device(device))
Y = torch.Tensor(np.where(Y.cpu().detach().numpy()>0, 1, 0))#.to(device)

#@title Neptune Ai

torch.cuda.empty_cache()





#@title Rearranging data
batch_size = int(input('Batch size - '))
number_of_channels = 1
IMG_Height = X.size(dim=2)
IMG_Width = X.size(dim=1)
Data_Junks = int(len(X)/batch_size)
number_of_patients = int(len(X)/130)
print('Number_of_batches = 0 -',Data_Junks)
Number_of_batches = int( input( ' Data_Junks - ') )

X_test = X[batch_size*Number_of_batches:batch_size*Data_Junks].view(-1,batch_size,number_of_channels,IMG_Height,IMG_Width)
Y_test = Y[batch_size*Number_of_batches:batch_size*Data_Junks].view(-1,batch_size,number_of_channels,IMG_Height,IMG_Width)

X = X[0*batch_size:batch_size*Number_of_batches].view(-1,batch_size,number_of_channels,IMG_Height,IMG_Width)
Y = Y[0*batch_size:batch_size*Number_of_batches].view(-1,batch_size,number_of_channels,IMG_Height,IMG_Width)

 
#@title Define model
model = Deeplabv3(batch_size,number_of_channels,IMG_Height).to(device)
loss_vector = []

#@title Optimizer
import torch.optim as optim
learning_rate = float(input('Learning Rate - '))
loss_function = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
eps = int(input('Epochs - '))



def intersection_accuracy(predicted,ground_truth):
     predicted = torch.round(predicted).cpu().detach().numpy()
     ground_truth = torch.round(ground_truth).cpu().detach().numpy()
     acc_metric = np.where(predicted==ground_truth,1,-1)
     accuracy = np.sum(acc_metric)/np.prod(ground_truth.shape)
     return accuracy



#@title Training


for epoch in range(eps): # 3 full passes over the data
  #  model.train()
    for data in range(Number_of_batches):  # `data` is a batch of data
        model.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.
        output = model.forward(X[data].to(device).float())  # pass in the reshaped batch (recall they are 28x28 atm)
        
        #run["training/batch/acc"].log(acc)

        loss =  F.mse_loss(output,Y[data].to(device).float())
        run["training/batch/loss"].log(loss)
        acc = intersection_accuracy(Y[data].to(device),output)
        run["training/batch/acc"].log(acc)

        loss.backward()  # apply this loss backwards thru the network's parameters
        optimizer.step()  # attempt to optimize weights to account for loss/gradients
    print(epoch,loss)
    loss_vector.append(loss) 




#@title Logging data to neptune ai

torch.cuda.empty_cache()


#@title Plot results
import matplotlib.pyplot as plt
import matplotlib as mpl

rnd = np.random.randint(Data_Junks, size=50)
X = X_test
Y = Y_test
for ix in rnd:
  print(X[ix][1].shape)
  model.eval()
  out = model(X[ix].to(device))
  out = out*255#torch.unsqueeze(X[ix],0).to('cuda:0')[:,a:a+b,a:a+b]
  #print(torch.unsqueeze(X[ix],0).to('cuda:0')[:,a:a+b,a:a+b].shape)
  out = out[1][0].cpu().detach().numpy()

  fig = plt.figure()

  ax1 = fig.add_subplot(1,3,1)
  plt.title("Test data")
  ax1.imshow(X[ix][1][0].cpu().detach().numpy())
  #plt.show()
  ax2 = fig.add_subplot(1,3,2)
  plt.title("Ground Truth")
  ax2.imshow((Y[ix][1][0].cpu().detach().numpy()))
  #plt.show()
  ax3 = fig.add_subplot(1,3,3)
  plt.title("Predicted")
  ax3.imshow(out)
  plot = plt.show()